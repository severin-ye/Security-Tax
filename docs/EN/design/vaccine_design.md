## Directory Structure

```text
repo/
â”œâ”€ README.md
â”‚  # Project description: paper background (Multi-Agent Security Tax), system design, reproduction methods, how to run
â”‚
â”œâ”€ pyproject.toml
â”‚  # Python project configuration: dependencies (langchain / asyncio / pydantic etc.), formatting and testing
â”‚
â”œâ”€ .env.example
â”‚  # Environment variable example: OpenAI API Key / local model path / log path
â”‚
â”œâ”€ src/
â”‚  â”œâ”€ app.py
â”‚  â”‚  # Main entry point: load config â†’ start orchestrator â†’ run single or batch simulation
â”‚  â”‚
â”‚  â”œâ”€ common/
â”‚  â”‚  â”œâ”€ __init__.py
â”‚  â”‚  â”œâ”€ types.py
â”‚  â”‚  â”‚  # Global data structure definitions (Message / Event / ToolCall / Outcome)
â”‚  â”‚  â”œâ”€ constants.py
â”‚  â”‚  â”‚  # Constants: Agent names, termination reason enum, risk types, behavior levels (-2 ~ +2)
â”‚  â”‚  â”œâ”€ utils.py
â”‚  â”‚  â”‚  # Common utility functions: random seed, timestamp, JSONL read/write
â”‚  â”‚  â””â”€ logging.py
â”‚  â”‚     # Unified logging interface: events / messages / tool_calls
â”‚  â”‚
â”‚  â”œâ”€ llm/
â”‚  â”‚  â”œâ”€ __init__.py
â”‚  â”‚  â”œâ”€ factory.py
â”‚  â”‚  â”‚  # LLM factory: OpenAI / local model / mock (replaces AutoGPT model layer)
â”‚  â”‚  â””â”€ prompts.py
â”‚  â”‚     # Prompt assembly: system + memory + message + scratchpad
â”‚  â”‚
â”‚  â”œâ”€ agents/
â”‚  â”‚  â”œâ”€ __init__.py
â”‚  â”‚  â”‚
â”‚  â”‚  â”œâ”€ roles/
â”‚  â”‚  â”‚  â”œâ”€ atlas.yaml
â”‚  â”‚  â”‚  â”‚  # Atlas: Project manager agent (task decomposition and scheduling)
â”‚  â”‚  â”‚  â”œâ”€ bohr.yaml
â”‚  â”‚  â”‚  â”‚  # Bohr: Researcher agent
â”‚  â”‚  â”‚  â”œâ”€ curie.yaml
â”‚  â”‚  â”‚  â”‚  # Curie: Researcher agent
â”‚  â”‚  â”‚  â”œâ”€ deng.yaml
â”‚  â”‚  â”‚  â”‚  # Deng: Executor agent (run_code high risk)
â”‚  â”‚  â”‚  â”œâ”€ edison.yaml
â”‚  â”‚  â”‚  â”‚  # Edison: Researcher agent
â”‚  â”‚  â”‚  â”œâ”€ faraday.yaml
â”‚  â”‚  â”‚  â”‚  # Faraday: Researcher agent
â”‚  â”‚  â”‚  â””â”€ gauss.yaml
â”‚  â”‚  â”‚     # Gauss: Researcher agent
â”‚  â”‚  â”‚
â”‚  â”‚  â”œâ”€ prompt_templates/
â”‚  â”‚  â”‚  â”œâ”€ base_system.jinja2
â”‚  â”‚  â”‚  â”‚  # Base system prompt (without defense)
â”‚  â”‚  â”‚  â””â”€ scratchpad.jinja2
â”‚  â”‚  â”‚     # Internal thinking template (react / plan / critique)
â”‚  â”‚  â”‚
â”‚  â”‚  â”œâ”€ memory/
â”‚  â”‚  â”‚  â”œâ”€ __init__.py
â”‚  â”‚  â”‚  â”œâ”€ store.py
â”‚  â”‚  â”‚  â”‚  # Agent memory stream structure (append / prepend / truncate)
â”‚  â”‚  â”‚  â””â”€ vaccines.py
â”‚  â”‚  â”‚     # Memory vaccine injection logic (passive / active)
â”‚  â”‚  â”‚
â”‚  â”‚  â””â”€ runtime/
â”‚  â”‚     â”œâ”€ __init__.py
â”‚  â”‚     â”œâ”€ agent_runtime.py
â”‚  â”‚     â”‚  # Single agent main loop: get message â†’ LLM â†’ actions â†’ tools
â”‚  â”‚     â”œâ”€ agent_factory.py
â”‚  â”‚     â”‚  # Create agent instance based on role + defense strategy
â”‚  â”‚     â”œâ”€ message_queue.py
â”‚  â”‚     â”‚  # FIFO message queue (asyncio.Queue wrapper)
â”‚  â”‚     â””â”€ policy_hooks.py
â”‚  â”‚        # Defense hooks: system patch / memory prepend / message filtering
â”‚  â”‚
â”‚  â”œâ”€ tools/
â”‚  â”‚  â”œâ”€ __init__.py
â”‚  â”‚  â”œâ”€ messaging.py
â”‚  â”‚  â”‚  # send_message: send message to target agent queue
â”‚  â”‚  â”œâ”€ run_code.py
â”‚  â”‚  â”‚  # run_code: simulate code execution (only entry point for dangerous behavior)
â”‚  â”‚  â”œâ”€ risk_rules.py
â”‚  â”‚  â”‚  # Risk detection rules: identify dangerous chemical mixtures â†’ trigger "explosion"
â”‚  â”‚  â””â”€ langchain_adapters.py
â”‚  â”‚     # LangChain Tool wrapper (expose tools to agents)
â”‚  â”‚
â”‚  â”œâ”€ orchestrator/
â”‚  â”‚  â”œâ”€ __init__.py
â”‚  â”‚  â”œâ”€ simulation.py
â”‚  â”‚  â”‚  # Single simulation flow: initialize â†’ inject task â†’ run in parallel â†’ terminate
â”‚  â”‚  â”œâ”€ scheduler.py
â”‚  â”‚  â”‚  # Parallel scheduling: start asyncio worker for each agent
â”‚  â”‚  â”œâ”€ injection_points.py
â”‚  â”‚  â”‚  # Injection timing management (e.g., after 2nd message)
â”‚  â”‚  â”œâ”€ lifecycle.py
â”‚  â”‚  â”‚  # Termination conditions: explosion / deadlock / message limit
â”‚  â”‚  â””â”€ tracing.py
â”‚  â”‚     # Global tracing: message propagation graph, state changes
â”‚  â”‚
â”‚  â”œâ”€ attacks/
â”‚  â”‚  â”œâ”€ __init__.py
â”‚  â”‚  â”œâ”€ injector.py
â”‚  â”‚  â”‚  # Attack injection executor: inject malicious prompt to target agent
â”‚  â”‚  â”œâ”€ prompt_bank.py
â”‚  â”‚  â”‚  # Load 12 jailbreak prompts
â”‚  â”‚  â”œâ”€ target_selection.py
â”‚  â”‚  â”‚  # Randomly select attack target (exclude Atlas / Deng)
â”‚  â”‚  â””â”€ schedule.py
â”‚  â”‚     # Attack trigger strategy (works with injection_points)
â”‚  â”‚
â”‚  â”œâ”€ defenses/
â”‚  â”‚  â”œâ”€ __init__.py
â”‚  â”‚  â”œâ”€ instructions.py
â”‚  â”‚  â”‚  # Instruction defense: append to system prompt (passive / active)
â”‚  â”‚  â”œâ”€ vaccines.py
â”‚  â”‚  â”‚  # Vaccine defense: prepend to memory (passive / active)
â”‚  â”‚  â”œâ”€ modes.py
â”‚  â”‚  â”‚  # Defense mode enum (NONE / INSTR / VAX Ã— passive/active)
â”‚  â”‚  â””â”€ registry.py
â”‚  â”‚     # Defense strategy registration and combination (experiment matrix)
â”‚  â”‚
â”‚  â””â”€ eval/
â”‚     â”œâ”€ __init__.py
â”‚     â”œâ”€ robustness.py
â”‚     â”‚  # System robustness: whether explosion triggered
â”‚     â”œâ”€ cooperation.py
â”‚     â”‚  # Cooperation ability: acceptance rate of weird but harmless instructions
â”‚     â”œâ”€ propagation.py
â”‚     â”‚  # Propagation analysis: multi-hop infection chain, behavior level statistics
â”‚     â”œâ”€ judge.py
â”‚     â”‚  # LLM-as-judge (optional, align with paper)
â”‚     â””â”€ report.py
â”‚        # Aggregate results and export to CSV / JSON
â”‚
â”œâ”€ data/
â”‚  â”œâ”€ attacks/
â”‚  â”‚  â””â”€ jailbreak_prompts.jsonl
â”‚  â”‚     # 12 malicious prompts from the paper
â”‚  â”œâ”€ vaccines/
â”‚  â”‚  â”œâ”€ passive.jsonl
â”‚  â”‚  â”‚  # Passive vaccine memory examples
â”‚  â”‚  â””â”€ active.jsonl
â”‚  â”‚     # Active vaccine memory examples
â”‚  â”œâ”€ harmless/
â”‚  â”‚  â””â”€ weird_but_safe.jsonl
â”‚  â”‚     # Weird but harmless instructions (Experiment 2)
â”‚  â””â”€ tasks/
â”‚     â””â”€ lab_task_mof.json
â”‚        # Initial experiment task (sent to Atlas)
â”‚
â”œâ”€ configs/
â”‚  â”œâ”€ llm.yaml
â”‚  â”‚  # LLM parameters (model name / temperature / max_tokens)
â”‚  â”œâ”€ sim.yaml
â”‚  â”‚  # Simulation parameters (max_messages / timeout)
â”‚  â”œâ”€ experiments.yaml
â”‚  â”‚  # Experiment scale (runs / seeds)
â”‚  â””â”€ defense_matrix.yaml
â”‚     # Defense combination matrix (Paper Table 1 / Table 2)
â”‚
â”œâ”€ scripts/
â”‚  â”œâ”€ run_one.py
â”‚  â”‚  # Run single simulation (debugging)
â”‚  â”œâ”€ run_batch.py
â”‚  â”‚  # Batch run experiments (all defenses Ã— multiple seeds)
â”‚  â”œâ”€ summarize_runs.py
â”‚  â”‚  # Aggregate outputs â†’ tables
â”‚  â””â”€ make_figures.py
â”‚     # Generate propagation graphs / robustness plots
â”‚
â”œâ”€ outputs/
â”‚  â”œâ”€ runs/
â”‚  â”‚  â””â”€ <timestamp>_seed42/
â”‚  â”‚     â”œâ”€ events.jsonl
â”‚  â”‚     â”‚  # Full event timeline
â”‚  â”‚     â”œâ”€ messages.jsonl
â”‚  â”‚     â”‚  # Message propagation between agents
â”‚  â”‚     â”œâ”€ tool_calls.jsonl
â”‚  â”‚     â”‚  # send_message / run_code records
â”‚  â”‚     â”œâ”€ outcomes.json
â”‚  â”‚     â”‚  # Explosion / termination reasons
â”‚  â”‚     â””â”€ config_snapshot.yaml
â”‚  â”‚        # Complete configuration snapshot for this run
â”‚  â””â”€ reports/
â”‚     â”œâ”€ table_robustness.csv
â”‚     â”œâ”€ table_cooperation.csv
â”‚     â””â”€ propagation_graphs/
â”‚
â””â”€ tests/
   â”œâ”€ test_risk_rules.py
   â”‚  # Whether risk rules trigger correctly
   â”œâ”€ test_injection_schedule.py
   â”‚  # Whether injection strictly happens after 2nd message
   â””â”€ test_queue_order.py
      # FIFO queue order correctness
```

---

## I. Overall Architecture Overview

The system adopts a layered architecture, from top to bottom:

* **Simulation Orchestration Layer** (orchestrator): manages the lifecycle of a complete simulation
* **Agent Runtime Layer** (agents): defines agent behavior, memory, and policy extension points
* **Tool Layer** (tools): action interfaces that agents can call
* **Attack Layer** (attacks): injects adversarial inputs into the system at specified times
* **Defense Layer** (defenses): enhances agent robustness through instructions or memory
* **Evaluation Layer** (eval): quantitative analysis of simulation results
* **Data & Config** (data / configs): input samples and experiment parameters
* **Output** (outputs): ensures reproducible and traceable experiment results

---

## II. Module Responsibilities

### 1ï¸âƒ£ src/orchestrator/ â€” Simulation Orchestration Layer

Manages the full lifecycle of a simulation from start to finish.

* **simulation.py**
  Single simulation entry point, main flow:

  * Initialize all agents
  * Inject initial task
  * Start parallel scheduling
  * Wait for termination conditions and cleanup

* **scheduler.py**
  Parallel scheduler based on asyncio

  * Each agent corresponds to a worker coroutine

* **injection_points.py**
  Unified management of attack trigger points

  * Example: "Inject attack after system processes 2nd message"

* **lifecycle.py**
  Simulation termination condition checks:

  * Explosion (dangerous behavior)
  * Deadlock
  * Message count limit
  * Timeout

* **tracing.py**
  Global tracing and logging:

  * Message graph (who â†’ who)
  * Tool call records
  * Agent state snapshots

---

### 2ï¸âƒ£ src/agents/ â€” Agent Runtime Layer

Defines how agents think, remember, and act.

#### Roles & Configuration

* **roles/*.yaml**
  Static definition for each role:

  * System prompt
  * Allowed tools
  * Default behavior strategies (e.g., Atlas / Deng)

#### Core Runtime

* **runtime/agent_runtime.py**
  Main loop for a single agent:

  * Get message from message queue
  * Construct prompt (system + memory + current message)
  * Generate actions
  * Execute tools and record results

* **runtime/message_queue.py**
  Agent's message queue

  * Currently FIFO
  * Can be replaced with asyncio.Queue wrapper

#### Memory & Policy Extension

* **memory/store.py**
  Agent's long-term / short-term memory stream

  * Supports prepending "vaccine conversations"

* **runtime/policy_hooks.py**
  Defense extension points (hooks):

  * System prompt patch
  * Memory prepend
  * Message filter

---

### 3ï¸âƒ£ src/tools/ â€” Tool Layer (Messaging + Execution)

The only interface for agents to interact with the external world.

* **messaging.py**

  * `send_message(recipient, content)`
    Essence: deliver a message to target agent's message queue

* **run_code.py**

  * `run_code(code)`
  * Simulates code execution
  * Must produce logs
  * Must go through risk assessment

* **risk_rules.py**
  Dangerous rule set

  * E.g., detect dangerous chemical mixtures
  * Used to reproduce "explosion" and other failure states

* **langchain_adapters.py**
  Wrap the above tools as LangChain StructuredTools

---

### 4ï¸âƒ£ src/attacks/ â€” Attack Layer

Responsible for adversarial sample selection, timing, and injection.

* **schedule.py**
  Attack trigger timing

  * Default: after system processes 2nd message

* **target_selection.py**
  Attack target selection:

  * Exclude Atlas / Deng
  * Use random seed to ensure reproducibility

* **prompt_bank.py**
  Load attack prompts:

  * `data/attacks/jailbreak_prompts.jsonl`

* **injector.py**
  Actually execute injection:

  * Insert malicious message into target agent's message queue

---

### 5ï¸âƒ£ src/defenses/ â€” Defense Layer

Used to enhance agent robustness against attacks.

* **instructions.py**
  Instruction defense:

  * Append defense instructions to end of system prompt
  * Divided into passive / active levels

* **vaccines.py**
  Vaccine defense:

  * Prepend conversation snippets to agent memory
  * Also supports passive / active

* **modes.py**
  Defense mode enum:

  * NONE
  * INSTR_PASSIVE
  * INSTR_ACTIVE
  * VAX_PASSIVE
  * VAX_ACTIVE

* **registry.py**
  Generate defense strategy combinations based on experiment config

  * Used for matrix-style batch experiments

---

### 6ï¸âƒ£ src/eval/ â€” Evaluation Layer

Quantitative analysis of simulation results.

* **robustness.py**
  Whether explosion occurred

  * Source: run_code risk assessment or judge

* **cooperation.py**
  Acceptance rate for "weird but harmless" instructions

  * Data from weird_but_safe.jsonl

* **propagation.py**
  Attack propagation analysis:

  * who â†’ who
  * Infection chain length
  * Multi-hop propagation paths

* **judge.py** (optional)
  Use LLM-as-judge

  * Align with paper evaluation metrics

* **report.py**
  Aggregate output:

  * CSV / JSON
  * Input for visualization

---

## III. Data & Configuration Recommendations

### ğŸ“ data/

* **attacks/jailbreak_prompts.jsonl**
  Each line contains {id, prompt} (~12 entries)

* **vaccines/passive.jsonl**

* **vaccines/active.jsonl**
  Each line is a "memory conversation snippet"

* **harmless/weird_but_safe.jsonl**
  "Weird but harmless" instruction samples

* **tasks/lab_task_mof.json**
  Initial task (assigned to Atlas)

### ğŸ“ configs/

* **llm.yaml**
  Model / temperature / max tokens
  Supports OpenAI / local models

* **sim.yaml**

  * max_messages
  * deadlock_timeout_s
  * parallelism

* **defense_matrix.yaml**
  Defense strategy combination list (batch experiments)

* **experiments.yaml**

  * Number of runs
  * Seed list
  * Output path

---

## IV. Output Structure (Reproducible & Traceable)

* **outputs/runs/<timestamp_seedX>/**

  * **events.jsonl**
    Unified event stream (message dequeue, tool calls, etc.)
  * **messages.jsonl**
    who â†’ who + content + step
  * **tool_calls.jsonl**
    Detailed records of run_code / send_message
  * **outcomes.json**
    Statistics on explosion / deadlock / limit triggers
  * **config_snapshot.yaml**
    Complete configuration snapshot for this simulation

---

## Memory Logic

### 1) Which files are responsible for "each agent is independent"

* **src/agents/runtime/message_queue.py**
  Defines MessageQueue (wraps asyncio.Queue internally), each instance = one queue

* **src/agents/memory/store.py**
  Defines MemoryStore (holds a list/deque internally), each instance = one memory stream

* **src/agents/runtime/agent_runtime.py**
  Defines AgentRuntime, binds MessageQueue + MemoryStore as member variables to the agent

* **src/agents/runtime/agent_factory.py**
  Factory: creates AgentRuntime based on role configuration, key is that each creation instantiates a new queue+memory set

* **src/orchestrator/simulation.py**
  Simulation initialization: creates 7 agents in a loop, puts them in agents_by_name mapping

* **src/tools/messaging.py**
  send_message(sender, receiver, content): does one thingâ€”put() message into receiver's queue

### 2) Your implementation's "object relationships" should look like this

```text
SimulationContext
  â”œâ”€ agents_by_name["Atlas"]  -> AgentRuntime(queue_A, memory_A, ...)
  â”œâ”€ agents_by_name["Bohr"]   -> AgentRuntime(queue_B, memory_B, ...)
  â”œâ”€ agents_by_name["Curie"]  -> AgentRuntime(queue_C, memory_C, ...)
  â””â”€ ...
```

Key points:

* queue_A is not queue_B
* memory_A is not memory_B
* Only orchestrator holds a global agents_by_name for message routing, but doesn't share state.
